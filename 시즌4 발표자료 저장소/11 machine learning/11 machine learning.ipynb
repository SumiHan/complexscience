{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 11 기계학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이란? 모델은 다양한 변수 간의 수학적(혹은 확률적) 관계를 표현한 것이다. \n",
    "\n",
    "\n",
    "예) 소셜 네트워킹을 이용한 수익을 창출하고자 할 때 사용자의 수나 사용자 당 광고 수익 혹은 직원 수 같은 입력 변수로 \n",
    "\n",
    "차후 몇 년 동안의 연간 수익을 예측하는 비즈니스 모델을 만들곤 한다. \n",
    "\n",
    "요리책의 경우 먹는 사람의 수나 배고픈 정도 같은 입력 변수로 재료의 양을 결정하는 모델을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 기계학습이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 통해 모델을 만들고 사용하는 것으로 학습에 사용될 데이터의 정답이 포함되어 있는 지도 학습과 포함되어 있지 않은 비지도 학습을 살펴볼 것이다. \n",
    "\n",
    "많이 사용하는 분야\n",
    "\n",
    "이메일이 스팸메일인지 아닌지\n",
    "\n",
    "신용카드 사기 예측\n",
    "\n",
    "쇼핑 고객이 클릭할 확률이 높은 광고 예측\n",
    "\n",
    "슈퍼볼에서 우승할 미식 축구팀 예측\n",
    "\n",
    "아주 단순한 상황에서도 우리가 사용할 수 있는 모델은 무수히 많다. 일반적으로는 파라미터가 있는 모델을 고른 후 데이터를 통해 파라미터의 최적값을 찾으려고 한다. \n",
    "\n",
    "예) 키와 몸무게는 선형함수로\n",
    "   환자의 병은 의사결정나무로 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  오버피팅과 언더피팅                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "기계학습의 일반적인 문제는 오버피팅이다. 오버피팅이란 만들어진 모델의 성능이 학습 데이터에서는 좋지만 기존에 관측한 적이 없는 새로운 데이터에서는 좋지 않은 경우를 의미한다. \n",
    "\n",
    "이러한 현상은 데이터의 잡음까지 학습되거나 원하는 결과를 예측해 주는 요소가 아닌 요소들이 학습되기 때문에 발생한다. \n",
    "\n",
    "언터피팅은 보통 모델의 성능이 학습 데이터에서도 좋지 않은 경우를 의미한다. 보통 언더피팅이 발생하면 해당 모델은 문제에 적합하지 않다는 것을 의미하며 새로운 모델을 찾아봐야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"1.png\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "파란색 가로줄은 degree가 0인 다항 함수(상수 함수) 중 표본 데이터에 가장 적합한 함수를 나타낸다. \n",
    "\n",
    "학습 데이터에 상수 함수를 적용하면 심각한 언더피팅이 발생.\n",
    "\n",
    "빨간색 표본 데이터에 가장 적합한 빨간색 9차 함수(파라미터10개)는 정확하게 모든 학습 데이터를 통과하지지만 심각한 오버피팅이 발생\n",
    "\n",
    "초록색이 가장 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "가장 적합한 방법은 모델을 나누는 것이다. 예를 들어 전체 데이터의 2/3로 모델을 학습시키고 나머지 1/3로 모델의 성능을 평가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data splitting                                                                                                    \n",
    "from collections import Counter\n",
    "import math, random\n",
    "\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "                                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "대부분의 경우 입력 변수로 행렬 x 출력 변수로 벡터 y가 주어질 것이다. 이 때 traning data나 test data에 x나 y가 쌍을 이뤄서 들어갈 수 있도록 해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_pct):\n",
    "    data = list(zip(x, y))                        # pair corresponding values\n",
    "    train, test = split_data(data, 1 - test_pct)  # split the dataset of pairs\n",
    "    x_train, y_train = list(zip(*train))          # magical un-zip trick\n",
    "    x_test, y_test = list(zip(*test))\n",
    "    return x_train, x_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 다음과 같이 모델을 학습하고 성능을 평가할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모델이 학습 데이터에서 오버피팅됐다면 (왁벽히 별개인) 평가 데이터에서 모델의 성능은 좋지 않을 것이다. \n",
    "== 평가 데이터에 대한 성능이 좋은 모델은 오버피팅되지 않았다고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1.4 정확도 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이 메일은 스팸 메일인가? 저 지원자를 채용해야 하는가에 대한 모델을 만든다고 할 때 4가지 가능성이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"true.jpg\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "출처:http://www.nature.com/nrneph/journal/v10/n4/fig_tab/nrneph.2013.281_F1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이름이 Luke인 아이가 백혈병이 걸릴 확률을 계산해 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion table을 이용하여 백혈병에 걸릴 확률을 생각해 보자. 최근 동향을 보면 신생아 천명 중 5명에게 Luke라는 이름을 지어준다. \n",
    "\n",
    "그리고 사람이 살면서 백혈병에 걸릴 확률은 1.4%이므로 14명이 백혈병에 걸린다. \n",
    "\n",
    "만약에 이 두 가지 요소가 독립적이라고 가정하고 가정하고 \n",
    "\n",
    "루크라는 이름을 가진 사람은 백혈병에 걸린다라는 판독 방법을 백만명에게 다음과 같은 혼동행렬을 얻을 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"luke.png\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 혼동행렬을 사용해서 모델의 성능에 대한 다양한 지표를 계산할 수 있다. \n",
    "\n",
    "예) 정확한 예측의 비율을 의미하는 정확도를 다음과 같이 계산할 수 있다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correctness\n",
    "def accuracy(tp, fp, fn, tn):\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy(70, 4930, 13930, 981070)', 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy(70, 4930, 13930, 981070)\", accuracy(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.98114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상당히 높은 정확도로 계산되었다. 하지만 이 판독 방법은 확실히 좋은 방법이 아니기 때문에 계산된 결과에 크게 신경쓰지 말자. \n",
    "보통 모델의 성능을 평가하기 위해 정밀도(precision)와 재현율(recall)을 사용한다. 정밀도는 양성으로 예측된 결과의 정확도를 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('precision(70, 4930, 13930, 981070)', 0)\n"
     ]
    }
   ],
   "source": [
    "def precision(tp, fp, fn, tn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "print(\"precision(70, 4930, 13930, 981070)\", precision(70, 4930, 13930, 981070))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 재현율은 실제 양성 중 모델이 정확하게 양성으로 예측한 비율을 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('recall(70, 4930, 13930, 981070)', 0)\n"
     ]
    }
   ],
   "source": [
    "def recall(tp, fp, fn, tn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "print(\"recall(70, 4930, 13930, 981070)\", recall(70, 4930, 13930, 981070))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도와 재현율이 굉장히 낮은 것을 확인할 수 있으며 이 결과로 판독 방법이 형편없다는 것을 알 수 있다. \n",
    "\n",
    "때로는 정밀도와 재현율을 결합해서 다음과 같이 정의된 다음과 같이 정의된 F1점수를 사용하기도 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-23-56484a062202>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-56484a062202>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print(\"f1_score(70, 4930, 13930, 981070)\", f1_score(70, 4930, 13930, 981070))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def f1_score(tp, fp, fn, tn):\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "\n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "print(\"f1_score(70, 4930, 13930, 981070)\", f1_score(70, 4930, 13930, 981070))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 11.5 Bias-variance 트레이드오프\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모델의 bias가 매우 심하다면, 새로은 변수를 추가하는 것도 하나의 해결책일 것이다. \n",
    "\n",
    "11.3오버피팅과 언더피팅에서 봤듯이 상수 함수를 1차 함수로 바꾸면 모델의 성능이 상당히 개선되는 것을 확인할 수 있었다. \n",
    "\n",
    "반대로 모델의 variance 이 너무 높다면 모델의 변수를 줄이거나 더 많은 데이터를 구해서 모델을 다시 학습시키면 된다. \n",
    "\n",
    "반대로 모델의 variance 가 너무 높다면 모델의 변수를 줄이거나 (가능하다면) 더 많은 데이터를 구해서 모델을 다시 학습시키면 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오버피팅 문제는 편향(Bias)과 분산(variance)의 트레이드오프로 볼 수도 있다. \n",
    "\n",
    "두 수치는 모두 모델을 더 큰 모집단에서 추출한 다양한 학습 데이터로 모델을 다시 학습시키면 어떠한 변화가 발생하는지 설명해 준다.\n",
    "\n",
    "예를 들어 11.3 오버피팅과 언더피팅에서 다루었던 상수 함수는 거의 모든 학습 데이터에서 큰 오류를 범할 것이다.\n",
    "\n",
    "즉 상수 함수가 상당히 bias가 되었다고 볼 수 있다. 하지만 임의의 두 학습 데이터에서는 비슷한 모델이 만들어질 것이다. \n",
    "\n",
    "즉, variance는 낮다는 것을 의미한다. Bias가 높고 variance가 낮다면 언더피팅을 의미한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모델의 Bias가 매우 심하다면(즉 학습 데이터에서도 모델의 성능이 좋지 않다면) 새로운 변수를 추가하는 것도 하나의 해결책일 것이다. \n",
    "\n",
    "오버피팅와 언더피팅에서 보았듯이 상수 함수를 1차 함수로 바꾸면 모델의 성능이 상당히 개선되는 것을 확인할 수 있었다. \n",
    "\n",
    "반대로 모델의 variance이 너무 높다면 모델의 변수를 줄이거나 더 많은 데이터를 구해서 모델을 다시 학습시키면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림11-2는 9차 함수를 데이터 개수가 다른 다양한 학습 데이터로 학습시킨 결과를 보여 주고 있다. \n",
    "\n",
    "이전에 살펴봤던 것처럼 10개의 데이터로 학습된 함수는 굴곡이 심한 것을 확인할 수 있다. \n",
    "\n",
    "하지만 100개의 데이터로 학습된 함수의 경우 오버피팅이 감소한 것을 확인할 수 있으면 \n",
    "\n",
    "1,000개의 데이터로 학습된 함수는 거의 1차 함수의 모양과 동일하다는 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 복잡성이 동일한 상태에서 데이터가 더욱 많아진다면 모델을 데이터에 오버피팅시키는 것은 더욱 더 어려워진다. \n",
    "\n",
    "반대로 데이터의 수가 늘어나도 bias는 줄어들지 않는다. \n",
    "\n",
    "만약 데이터의 패턴을 잡아내기에 모델의 특징이 부족하다면 아무리 많은 데이터를 추가해도 도움이 되지 않는다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 특성 추출 및 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 특성이란 모델의 모든 입력 변수를 의미한다. \n",
    "\n",
    "예) 사람의 경력으로 연봉을 예측하고 싶다면, 경력은 특성이 된다.\n",
    "\n",
    "데이터가 복잡해질수록 신기한 일이 일어난다. 예를 들어 이메일이 스팸메일인지 아닌지를 예측해 주는 필터를 만들고 있다고 해보자. \n",
    "\n",
    "대부분의 모델은 수많은 글자로 구성된 이메일 원본을 어떨게 처리해야 할지 모를 것이다. 필터를 만들기 위해서는 다음과 같은 특징을 추출해야 할 것이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이메일에 비아그라라는 단어가 포함되어 있는가?\n",
    "\n",
    "d가 몇 번 나왔는가\n",
    "\n",
    "보낸 사람의 이메일 도메인은 무엇인가?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
